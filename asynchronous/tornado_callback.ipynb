{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Asynchronous - python 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Green Threads\n",
    "Green threads are a primitive level of asynchronous programming. \n",
    "A green thread looks and feels exactly like a normal thread, except that the threads are scheduled by application code \n",
    "rather than by hardware. Gevent is a well known python library for using green threads. \n",
    "Gevent is basically green threads + eventlet, a non-blocking I/O networking library. \n",
    "Gevent monkey patches common python libraries to have non-blocking I/O. \n",
    "Here is an example using gevents to make requests to multiple urls at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gevent.monkey\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "gevent.monkey.patch_all()\n",
    "\n",
    "urls = ['http://www.google.com', 'http://www.yandex.ru', 'http://www.python.org']\n",
    "\n",
    "\n",
    "\n",
    "def print_head(url):\n",
    "\n",
    "    print('Starting {}'.format(url))\n",
    "\n",
    "    data = urlopen(url).read()\n",
    "\n",
    "    print('{}: {} bytes: {}'.format(url, len(data), data))\n",
    "\n",
    "\n",
    "\n",
    "jobs = [gevent.spawn(print_head, _url) for _url in urls]\n",
    "\n",
    "\n",
    "\n",
    "gevent.wait(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the gevent API looks and feels just like threading. However under the hood, it’s using coroutine’s \n",
    "rather than actual threads, and running them on an event loop for scheduling. This means you get the benefits of \n",
    "light-weight threading without needing to understand coroutines, but you still have all the other issues that threading \n",
    "brings. Gevent is a good library for those who already understand threading and want lighter weight threads.\n",
    "\n",
    "\n",
    "## Event Loop? Coroutines? Woah, slow down, I’m lost…\n",
    "Lets clear up some things about how asynchronous programming works. One way to do asynchronous programming is with an \n",
    "event loop. The event loop is exactly what it sounds like, there is a queue of events/jobs and a loop that just \n",
    "constantly pulls jobs off the queue and runs them. These jobs are called coroutines. They are a small set of \n",
    "instructions, including which events to put back on to the queue, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Style Async\n",
    "While many asynchronous libraries exist in Python, the most popular ones are probably Tornado and gevent. As we have already talked about gevent, lets focus a little on how Tornado works. Tornado is an asynchronous web framework that uses the callback style to do asynchronous network I/O. A callback is a function, and it means “Once this is done, execute this function”. It’s basically a “when done” hook for your code. In other words a callback is like when you call a customer service line, and immediately leave your number and hang up, so they can call you back when they are available, rather than having to wait on hold forever.\n",
    "\n",
    "Let’s take a look at how to do the same thing as above using tornado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tornado.ioloop\n",
    "\n",
    "from tornado.httpclient import AsyncHTTPClient\n",
    "\n",
    "urls = ['http://www.google.com', 'http://www.yandex.ru', 'http://www.python.org']\n",
    "\n",
    "\n",
    "\n",
    "def handle_response(response):\n",
    "\n",
    "    if response.error:\n",
    "\n",
    "        print(\"Error:\", response.error)\n",
    "\n",
    "    else:\n",
    "\n",
    "        url = response.request.url\n",
    "\n",
    "        data = response.body\n",
    "\n",
    "        print('{}: {} bytes: {}'.format(url, len(data), data))\n",
    "\n",
    "\n",
    "\n",
    "http_client = AsyncHTTPClient()\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "    http_client.fetch(url, handle_response)\n",
    "\n",
    "    \n",
    "\n",
    "tornado.ioloop.IOLoop.instance().start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the code a little, the very last line is calling a tornado method called AsyncHTTPClient.fetch which fetches a url in a non-blocking way. This method essentially executes and returns immediately allowing the program to do other things, while waiting on the network call. Because the next line is reached before the url has been hit, it is not possible to get a return object from the method. The solution to this problem is that instead of the fetch method returning an object, it calls a function with the result, or a callback. The callback in this example is handle_response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Hell\n",
    "In the previous example, you will notice that the very first line is checking for an error. This is required because it is not possible to raise an exception. If an exception was raised, it would not be handled by the proper section of code, due to the event loop. When fetch is executed, it starts the http call, then puts handling the response on the event loop. By the time we notice our error, the call stack would only be the event loop and this function, with none of our code to handle the exception. So any exceptions thrown in the callback will break the event loop and the program. Therefore all errors have to be passed as objects rather than raised. This means if you forget to check for errors, your errors will be swallowed. Anyone familiar with golang will recognize this style, as the language enforces it everywhere. This is the most complained about aspect of golang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other problem with callbacks is that in an asynchronous world, the only way to not block things is with a callback. This can lead to a very long chain of callback after callback after callback. Since you lose access to the stack and variables, you end up shoving large objects into all your callbacks, but if your using 3rd party APIs, you can’t pass anything into the callback that’s not expected. This also becomes a problem because every callback acts like a thread, but there is no way to “gather” the tasks. Lets say for example you wanted to call three APIs, then wait till the three are done, and return the aggregated results. In the gevent world, you could do this, but with callbacks you cannot. \n",
    "\n",
    "You would have to hack around it by saving results to some global state variables, and in the callback you would have to check if it’s the last result or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "Let’s compare so far. If we want to prevent I/O from blocking, we have to use either threads or async. Threads come with issues such as resource starvation, dead-locks, and race conditions. It also creates context switching overhead for the CPU. Async programming can solve the context switching error, but comes with its own problems. In python our options are green threads or callback style of async programming.\n",
    "### Green Threads Style\n",
    "Threads are controlled at the application level, rather than hardware\n",
    "Feel like threads; Good for those who understand threading\n",
    "Includes all the problems of normal thread-based programming other than CPU context switching\n",
    "### Callback Style\n",
    "Not like threaded programs at all\n",
    "Threads/coroutines are invisible to the programmer\n",
    "Callbacks swallow exceptions\n",
    "Callbacks are not gather-able\n",
    "Callback after callback gets confusing and hard to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we improve?\n",
    "Up until python 3.3 this really was the best you could do. In order to do better you need more language support. In order to do better, Python would need some way to execute a method partially, halting execution, and maintain stack objects and exceptions throughout. If you’re familiar with Python concepts, you might realize I am hinting at Generators. Generators allow a functions to return a list, one item at a time, halting execution until the next item is needed. The problem with generators is that they must be completely consumed by the function calling it. In other words, a generator can not call a generator, halting execution of both. That is however until PEP 380 added the *yield from* syntax that allows a generator to yield the result of another generator. While async isn’t really the intention of generators, it provides all the features needed to make async great. Generators maintain a stack and can raise exceptions. If you were to write an event loop that ran generators, you could have a great *async* library. And thus, the *asyncio* library was born. All you have to do is add a *@coroutine* decorator and asyncio will patch your generator into a coroutine. Here is an example of us calling the same three urls as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "\n",
    "urls = ['http://www.google.com', 'http://www.yandex.ru', 'http://www.python.org']\n",
    "\n",
    "\n",
    "\n",
    "@asyncio.coroutine\n",
    "\n",
    "def call_url(url):\n",
    "\n",
    "    print('Starting {}'.format(url))\n",
    "\n",
    "    response = yield from aiohttp.get(url)\n",
    "\n",
    "    data = yield from response.text()\n",
    "\n",
    "    print('{}: {} bytes: {}'.format(url, len(data), data))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "futures = [call_url(url) for url in urls]\n",
    "\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "loop.run_until_complete(asyncio.wait(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### A couple things to note here:\n",
    "1) We are not looking for errors, because errors get passed up the stack correctly.\n",
    "2) We can return an object if we want.\n",
    "3) We can start all coroutines, and gather them later.\n",
    "4) No callbacks\n",
    "5) Line 10 doesn’t execute until line 9 is completely done. (feels synchronous/familiar)\n",
    "\n",
    "Life is great! The only problem is the yield from looks way too much like a generator, and it could cause problems if it actually was a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async and Await"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asyncio library was gaining a lot of traction, so Python decided to make it a core library. With the introduction of the core library, they also added the keywords async and await in Python 3.5. The keywords are designed to make it more clear your code is asynchronous; so your methods are not confused with generators. The async keyword goes before def to show that a method is asynchronous. The await keyword replaces yield from and makes it more clear that you are waiting for a coroutine to finish. Here is our example again but with the async/await keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "\n",
    "urls = ['http://www.google.com', 'http://www.yandex.ru', 'http://www.python.org']\n",
    "\n",
    "\n",
    "\n",
    "async def call_url(url):\n",
    "\n",
    "    print('Starting {}'.format(url))\n",
    "\n",
    "    response = await aiohttp.get(url)\n",
    "\n",
    "    data = await response.text()\n",
    "\n",
    "    print('{}: {} bytes: {}'.format(url, len(data), data))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "futures = [call_url(url) for url in urls]\n",
    "\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "loop.run_until_complete(asyncio.wait(futures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically what is happening here is an async method, when executed, returns a coroutine which can then be awaited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We Have Arrived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python finally has an excellent asynchronous framework, asyncio. Lets take a look at all the problems of threading and see if we have solved them.\n",
    "#### CPU Context switching: \n",
    "asyncio is asynchronous and uses an event loop; it allows you to have application controlled context switches while waiting for I/O. No CPU switching found here!\n",
    "#### Race Conditions: \n",
    "Because asyncio only runs a single coroutine at a time and switches only at points you define, your code is safe from race conditions.\n",
    "#### Dead-Locks/Live-Locks: \n",
    "Since you don’t have to worry about race conditions, you don’t have to use locks at all. This makes you pretty safe from dead-locks. You could still get into a dead-lock situation if you require two coroutines to wake each other, but that is so rare you would almost have to try to make it happen.\n",
    "#### Resource Starvation: \n",
    "Because coroutines are all run on a single thread, and dont require extra sockets or memory, it would be a lot harder to run out of resources. Asyncio however does have an “executor pool” which is essentially a thread pool. If you were to run too many things in an executor pool, you could still run out of resources. However, using too many executors is an anti-pattern, and not something you would probably do very often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be fair, while asyncio is pretty great, it does come with its own problems. First, asyncio is new to python. There are some weird edge cases that will leave you wanting for more. Second, when you go fully asynchronous, it means your entire codebase has to be asynchronous. Every. Single. Piece. This is because synchronous functions might take up too much time, thereby blocking your event loop. The libraries for asyncio are still young and maturing, so it is sometimes hard to find an asynchronous version for part of your stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}